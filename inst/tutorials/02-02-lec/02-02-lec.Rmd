---
title: 'Lecture: Applied Bayesian Statistics II'
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    css: css/learnr-theme.css
runtime: shiny_prerendered
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE}
## --- Options ---
eval_ex <- TRUE
eval_sol <- TRUE
eval_learnr <- TRUE

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

## --- learnr ---
if ("learnr" %in% (.packages()))
  detach(package:learnr, unload = TRUE)
library(learnr)
```

```{r, echo=FALSE, context="server"}
## --- Options ---
eval_ex <- TRUE
eval_sol <- TRUE
eval_learnr <- TRUE
```

```{r setup, include=FALSE}
## ---- CRAN Packages ----
## Save package names as a vector of strings
pkgs <-
  c("rstan",
    "brms",
    "future",
    "bayesplot",
    "dplyr",
    "ggplot2",
    "modelsummary",
    "marginaleffects",
    "ggpubr")

## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())],
       install.packages,
       repos = 'http://cran.us.r-project.org')

## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)

## ---- Global learnr Objects ----
lab3_url <-
  "https://github.com/denis-cohen/statmodeling/raw/main/data/lab3.RData"
load(url(lab3_url))
```

## Overview

### What is brms?

<blockquote>
<sub>The brms package provides an interface to fit Bayesian generalized (non-)linear multivariate multilevel models using Stan. The formula syntax is very similar to that of the package lme4 to provide a familiar and simple interface for performing regression analyses.</sub>
</blockquote>

::: {style="text-align: right"}
<sub><sup>
[paul-buerkner.github.io/brms](https://paul-buerkner.github.io/brms)
</sub></sup>
:::

It was created and is being maintained by [Paul Bürkner](https://paul-buerkner.github.io/). It is extensively documented on its own [website](https://paul-buerkner.github.io/brms/).

### Comparison: Pre-implemented model types

```{r functionality, exercise = FALSE, echo = FALSE, out.width = '80%', fig.align="center"}
knitr::include_graphics("images/canned.png")
```

<div style="text-align: right">
  <sub><sup>
    Source: [Bürkner, Paul-Christian (2022). brms: An R Package for Bayesian Multilevel Models
using Stan.](https://cloud.r-project.org/web/packages/brms/vignettes/brms_overview.pdf)
  </sub></sup>
</div>

*Note:* This table is from a 2022 publication. Newer versions of `brms` handle [missing values](https://cloud.r-project.org/web/packages/brms/vignettes/brms_missings.html).

### brms vignettes as an indication of its versatility

#### General

- [General Introduction to brms](https://www.jstatsoft.org/article/view/v080i01)

#### Model types

- [Advanced Multilevel Modeling with brms](https://journal.r-project.org/archive/2018/RJ-2018-017/index.html)
- [Bayesian Item Response Modeling with brms](https://arxiv.org/abs/1905.09501)
- [Estimating Distributional Models with brms](https://paul-buerkner.github.io/brms/articles/brms_distreg.html)
- [Estimating Multivariate Models with brms](https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
- [Estimating Non-Linear Models with brms](https://paul-buerkner.github.io/brms/articles/brms_nonlinear.html)
- [Estimating Phylogenetic Multilevel Models with brms](https://paul-buerkner.github.io/brms/articles/brms_phylogenetics.html)

#### Auxiliary

- [Define Custom Response Distributions with brms](https://paul-buerkner.github.io/brms/articles/brms_customfamilies.html)
- [Parameterization of Response Distributions in brms](https://paul-buerkner.github.io/brms/articles/brms_families.html)
- [Handle Missing Values with brms](https://paul-buerkner.github.io/brms/articles/brms_missings.html)
- [Estimating Monotonic Effects with brms](https://paul-buerkner.github.io/brms/articles/brms_monotonic.html)
- [Running brms models with within-chain parallelization](https://paul-buerkner.github.io/brms/articles/brms_threading.html)

### A function call to brms

```{r, eval=FALSE, echo = TRUE}
lm_brms <- brms::brm(
  sup_afd ~                              # outcome
    la_self,                             # predictor
  data = gles,                           # data
  family = gaussian(link = "identity"),  # family and link
  chains = 4L,                           # number of chains
  iter = 2000L,                          # number of iterations per chain
  warmup = 1000L,                        # number of warm-up samples per chain
  algorithm = "sampling",                # algorithm (HMC/NUTS)
  backend = "rstan",                     # backend (rstan)
  seed = 20231123L                       # seed
)
```

### What happens under the hood

```{r under-hood, echo = FALSE, out.width = '75%', fig.align="center"}
knitr::include_graphics("images/procedure.png")
```

<div style="text-align: right"> 
  <sub><sup>
    Source: [Bürkner, Paul-Christian (2022). brms: An R Package for Bayesian Multilevel Models
using Stan.](https://cloud.r-project.org/web/packages/brms/vignettes/brms_overview.pdf)
  </sub></sup>
</div>

## Linear model

### Likelihood

The linear model stipulates that the observed outcomes $y_i$ for every unit $i$ can be expressed as realizations from a normal distribution with unit-specific *mean or location parameter* $\mu_i$ and a constant (i.e., general) *variance or scale parameter* $\sigma^2$.

$$y_i \sim \text{N}(\mu_i, \sigma^2) \text{ for all }i = 1,...N$$

or, alternatively,

$$y_i = \mu_i + \epsilon_i  \text{ for all }i = 1,...N \\ \epsilon_i \sim \text{N}(0, \sigma^2)$$

The latter notation makes explicit that each observed $y_i$ can be thought of as a combination of a *systematic component*, $\mu_i$, and a *stochastic error component*, $\epsilon_i$, which follows a zero-mean normal distribution with constant variance $\sigma^2$.

### The systematic component

The systematic component is represented by the mean parameter $\mu_i$. In fact, $\mu_i$ is merely a *transformed parameter*: It is a linear function of unit-specific data $\mathbf{x}_i$ and coefficients $\beta$.

The formula below illustrates this, using the row vector notation $\mathbf{x}_i^{\prime} \beta$ as shorthand for the scalar notation $\beta_1 + \beta_2 x_{i, 2} + ...+\beta_k x_{i,k}$.

$$\mu_i = \underbrace{\mathbf{x}_i^{\prime} \beta}_{= \beta_1 + \beta_2 x_{i, 2} + ...+\beta_k x_{i,k}}  \text{ for all }i = 1,...N$$

### Parameters and priors

In the linear model, all coefficients $\beta$ as well as the variance $\sigma^2$ are model parameters.

In Bayesian analysis, we must assign them priors (though `brms`, like Stan, will assign default uniform priors if we do not explicitly specify priors).

### Data

We model respondents' support for the AfD (`sup_afd`, measured on an 11-point scale ranging from -5 to 5) as a function of respondents' pro-redistribution preferences (`se_self`) and anti-immigration preferences (`la_self`), a multiplicative interaction term between the two, and some controls: Gender (`fem`), age (`age`), and East/West residence (`east`).

Both `se_self` and `la_self` are measured on 11-point scales:

-   `se_self` ranges from values (0) "less taxes and deductions, even if that means less social spending" to (10) "more social spending, even if that means more taxes and deductions".
-   `la_self` ranges from values (0) "facilitate immigration" to (10) "restrict immigration".

The model formula is given by

$$
\mathtt{sup\_afd}_i = \\\beta_1 + \beta_2 \mathtt{se\_self}_i + \beta_3 \mathtt{la\_self}_i + \\ \beta_4 \mathtt{fem}_i + \beta_5 \mathtt{east}_i + \beta_6 \mathtt{age}_i + \\ \beta_7 \mathtt{se\_self}_i \times \mathtt{la\_self}_i + \epsilon
$$

## Fitting

### Choosing priors

`brms` uses default priors for certain "classes" of parameters. To check these defaults,
we need to supply the model formula, data, and generative model (i.e., family and link function) to
`brms::get_prior()`.

```{r brms-model-1, exercise=TRUE, eval=eval_ex}
# Get default priors
default_priors <- brms::get_prior(
  sup_afd ~                              # outcome
    la_self *                            # immigration preferences
    se_self +                            # redistribution preferences
    fem +                                # gender
    east +                               # east/west residence
    age,                                 # age
  data = gles,                           # data
  family = gaussian(link = "identity")   # family and link
)
default_priors
```

*Note:* Missing entries in the `prior` column denote flat/uniform priors.

### Define custom priors

If we don't like the default priors, we can create a `brmsprior` object
by specifying the desired distributional properties of parameters of
various classes:

```{r brms-model-2, exercise=TRUE, eval=eval_ex, exercise.lines = 6}
custom_priors <- c(
  brms::prior(normal(0, 5), class = b),            # normal slopes
  brms::prior(normal(0, 5), class = Intercept),    # normal intercept
  brms::prior(cauchy(0, 5), lb = 0, class = sigma) # half-cauchy SD
)
custom_priors
```

Let's think about these values intuitively. How informative/vague are our priors?

### Prior predictive checks: Fitting

```{r brms-priorpc-1, exercise=TRUE, eval=FALSE, exercise.lines = 18, exercise.timelimit = 120}
lm_brms_prior_only <- brms::brm(
  sup_afd ~                              # outcome
    la_self *                            # immigration preferences
    se_self +                            # redistribution preferences
    fem +                                # gender
    east +                               # east/west residence
    age,                                 # age
  data = gles,                           # data
  family = gaussian(link = "identity"),  # family and link
  prior = custom_priors,                 # priors
  sample_prior = "only",                 # samply only from prior
  chains = 2L,                           # number of chains
  iter = 1000L,                          # number of iterations per chain
  warmup = 0L,                           # number of warm-up samples per chain
  algorithm = "sampling",                # algorithm (HMC/NUTS)
  backend = "rstan",                     # backend (rstan)
  seed = 20231123L                       # seed
)
```

### Check model predictions vis-à-vis empirical distribution of outcome

```{r brms-priorpc-2, echo = T, fig.align='center'}
brms::pp_check(
  lm_brms_prior_only, 
  ndraws = 100, 
  type = "dens_overlay"
) +
  ggplot2::xlim(-150, 150)
```

### Fitting the model

Lastly, we can fit the model using `brms::brm()`. 

*Note:* Model compilation and estimation may take a while.

```{r brms-model-3, exercise=TRUE, eval=FALSE, exercise.lines = 18, exercise.timelimit = 120}
lm_brms <- brms::brm(
  sup_afd ~                              # outcome
    la_self *                            # immigration preferences
    se_self +                            # redistribution preferences
    fem +                                # gender
    east +                               # east/west residence
    age,                                 # age
  data = gles,                           # data
  family = gaussian(link = "identity"),  # family and link
  prior = custom_priors,                 # priors
  chains = 4L,                           # number of chains
  iter = 2000L,                          # number of iterations per chain
  warmup = 1000L,                        # number of warm-up samples per chain
  algorithm = "sampling",                # algorithm (HMC/NUTS)
  backend = "rstan",                     # backend (rstan)
  seed = 20231123L                       # seed
)
```

## Summarize and diagnose

### Model summary and generic diagnostics

First, we print the model summary. We can check `Rhat` for any signs of non-convergence.

```{r brms-print}
lm_brms
```

### Visual diagnostics

Let's explore the following visualizations of common generic diagnostics:

```{r brms-visual, exercise=TRUE, eval=eval_ex, exercise.lines = 3}
brms::mcmc_plot(lm_brms, type = "rhat")  # Gelman-Rubin 
brms::mcmc_plot(lm_brms, type = "acf")   # Autocorrelation
brms::mcmc_plot(lm_brms, type = "trace") # Trace plots
```

See `help(mcmc_plot)` for additional types of plots.

### Algorithm-specific diagnostics

Note: We rely on the `check_hmc_diagnostics()` function from the `rstan` package. To ensure it works, we must extract the `stanfit` object nested in our `brmsfit` object via `lm_brms$fit`.

```{r algo-diag, exercise=TRUE, eval=eval_ex, exercise.lines = 3}
rstan::check_hmc_diagnostics(lm_brms$fit)
```

### What if I find signs of non-convergence?

The standard answer is: Increase the length of your chains. It may especially help with warnings about Rhat, ESS, and low BFMI.

But this is not always the optimal strategy, and it may not solve your problem.

So, suppose that after running longer chains, one or several of the following still apply:

- Your algorithm-specific diagnostics throw warnings (that won't go away)
- Your convergence diagnostics indicate signs of non-convergence (and increasing the warm-up period doesn't help)
- Your algorithm is painfully slow

### Dealing with non-covergence and computational problems

Here are some answers, partly based on [Gelman et al. (2020)](https://arxiv.org/abs/2011.01808) and the Stan Development Team's guide [*Runtime warnings and convergence problems*](https://mc-stan.org/misc/warnings.html):

- Do read [*Runtime warnings and convergence problems*](https://mc-stan.org/misc/warnings.html). It can help you understand a specific problem and potential solutions.
- Do you get algorithm-specific warnings about divergences/max_treedepth? Adjust the HMC/NUTS control arguments `adapt_delta`, `stepsize`, and/or `max_treedepth`.
- Check if your model is well specified (e.g., do you have problems of separation in logistic regression?)
- Adopt an efficient workflow for debugging:
  - Reduce model complexity. [Start with a simpler specification, gradually build up.](https://hyunjimoon.github.io/SBC/articles/small_model_workflow.html) See where things start to go wrong.
  - Use smaller sets of data, few chains, and short runs.
- Optimize priors:
    - If you use custom priors: Do your priors allow for posterior density in regions where you'd expect it?
    - If you use default flat or very vague priors: Use stronger priors (within reason)




## Presentation

### Vincent AB's universe

[Vincent Arel-Bundock](https://arelbundock.com/) has authored and maintains an excellent collection of R packages for the post-estimation presentation of statistical results, including:

- [`modelsummary`](https://modelsummary.com/): Beautiful, customizable, publication-ready data and model summaries in R
- [`marginaleffects`](https://marginaleffects.com/): R package to compute and plot predictions, slopes, marginal means, and comparisons

These packages not only come with incredible flexibility (see the links for details) but also apply to countless classes of statistical models in R (including both frequentist/likelihood-based and Bayesian models).

### Tables

```{r modelsummary}
modelsummary::modelsummary(
  list("Model 1" = lm_brms),
  statistic = c("SD" = "({std.dev})", 
                "95% CI" = "[{conf.low}, {conf.high}]"),
  coef_rename = c(
    "b_Intercept" = "Intercept",
    "b_la_self" = "Anti-immigration",
    "b_se_self" = "Pro-redistribution",
    "se_self" = "Pro-redistribution",
    "sigma" = "σ"
  ), 
  coef_omit = c("fem1|east1|age"),
  gof_map = "nobs",
  conf_level = 0.95,
  centrality = "mean",
  output = "flextable",
  align = "lc",
  title = paste(
    "Bayesian linear regression of AfD support on preferences for",
    "immigration restriction and redistribution."
  ),
  notes = paste(
    "Posterior means with posterior standard deviations and",
    "95% credible intervals in parentheses.",
    "Background covariates (omitted from table): age, gender, East/West."
  )
) %>%
  flextable::autofit()
```

### Quantities of interest (QOIs) -- a refresher

1. **Expected values**: Predicted levels of the outcome variable
  1. **For hypothetical observations**
  1. **Over the values of a focal predictor, holding all else constant** 
1. **Average first differences:** Effects of categorical predictors
  1. **For binary comparisons**
  1. **For multi-group comparisons** $\rightarrow$ pairwise binary comparisons
1. **Average marginal effects:** Effects of continuous predictors


### QOI example: logistic regression

Here, you see a visualization of a logistic regression of voting for Joe Biden ($y=1$) as opposed to Donald Trump ($y=0$) in the 2020 US Presidential Election as a function of two predictors: respondents' ethnicity and their average feelings towards various ethnic minority groups (rated on a scale from 0 "cold" to 100 "warm".

```{r logit1, echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics("images/double-logit-plot-1.png")
```

The left-hand side shows the *linear component*, a linear function of the coefficient estimates and chosen predictor values.

The right-hand side shows the *expected values*, which result from applying the *inverse link function* to this linear function.

The X marks a *hypothetical observation*: a non-hispanic white respondent who feels moderately warm towards ethnic minorities.

### QOI example: first differences

```{r logit2, echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics("images/background-plot-1.png")
```

The plots illustrate *observation-level first differences* in the probability of voting for Biden instead of Trump that result from a counterfactual comparison of ethnic minority vs non-hispanic white respondents.

In generalized linear models, observation-level first differences are sensitive to the choice of background covariate values (here: feelings towards ethnic minorities).

The *average first difference* takes the sample average of all observation-level first differences, thereby averaging over the variation induced by different covariate values.

### QOI example: conditional effects (discrete interaction effects)

```{r cqoi1, echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics("images/unnamed-chunk-33-1.png")
```

Here, we see the effect of age on the probability of voting Biden vs. Trump, conditional on a *discrete moderator*, respondents' place of residence (four categories).

On the left, we see the expected values. We see that support for Biden is generally lower in rural than in urban areas. Furthermore, the dependence of vote choice on age is greater in urban than in rural places: the prediction curve is flat in rural areas and downward-sloping in cities. This is also shown on the right-hand side, where we see the respective average marginal effects.


### QOI example: conditional effects (gradual interaction)

```{r cqoi2, echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics("images/unnamed-chunk-36-1.png")
```

Lastly, we see the effect of respondents' feeling towards ethnic minorities on the probability of voting Biden vs. Trump, conditional on a *continuous moderator*, respondents' age (in years).

On the left, we see the expected values, conditional on four exemplary values of the moderator. We see that the dependence of vote choice on feelings towards ethnic minorities decreases with age: the prediction curve is steepest for young respondents and flattest for old respondents. This is also shown on the right-hand side, where we see a gradual decline in the positive average marginal effect.



### Application: marginaleffects

The [`marginaleffects`](https://marginaleffects.com/) package ("Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests"), allows users to *"compute and plot predictions, slopes, marginal means, and comparisons (contrasts, risk ratios, odds, etc.) for over 100 classes of statistical and machine learning models in R"*.

A few years ago, compatibility with `brms` models was added.

Below, we apply the package commands to our model, `lm_brms`, which includes a *continuous interaction effect*.


### Conditional expected values

```{r cef-la, exercise=TRUE, eval=eval_ex, exercise.lines = 12}
marginaleffects::plot_predictions(
  lm_brms,
  condition = list("la_self",               # Main predictor
                   "se_self" = c(0, 5, 10)) # Exemplary values of moderator
  ) + 
  ggplot2::labs(x = "Anti-immigration preferences",
                y = "AfD Support",
                col = "Pro-redistribution\npreferences",
                fill = "Pro-redistribution\npreferences")
```

### Conditional marginal effects

```{r mfx-la, exercise=TRUE, eval=eval_ex, exercise.lines = 12}
marginaleffects::plot_slopes(lm_brms,
                             variable = "la_self",
                             condition = "se_self") +
  ggplot2::xlab("Pro-redistribution preferences") +
  ggplot2::ylab(
    paste(
      "Marginal effect of anti-immigration",
      "preferences on AfD support",
      sep = "\n"
    )
  )
```

Which substantive conclusions can we draw?

### Further reading

See the `marginaleffects` [Case Study 8: Bayes](https://marginaleffects.com/articles/brms.html) for a complete overview of the package's compatibility with `brms`.

## Posterior predictive checks

Posterior predictive checks involve simulating the data-generating process to
obtain replicated data given the estimated model. They can help us determine
how well our model fits the data.

This usually involves two questions:

1. Does the *family* yield an adequate generative model?
    - Does a Gaussian (normal) data-generating processes produce realistic replications of the observed values of `sup_afd` (support for the AfD on the -5 to +5 scale)?
    - Does the simulated distribution of the replications match the observed distribution of the outcome in the *sample*?
1. Does the *systematic component* accurately predict outcomes?
    - Do our predictors accurately predict which individuals are more likely to support the AfD?
    - How large is the *observation-level discrepancy* between simulated replications and observed data?

### Distributional congruence

To check whether the generative model produces distributions of replicated outcomes that match the distribution of the observed outcome, we can compare the density of the observed outcome with those of, say, `ndraws = 100` simulations. Each simulation is based on one post-warm-up sample from the posterior distribution.

```{r brms-lm-pp-1, echo = T, fig.align='center', fig.width = 8, fig.height=6}
brms::pp_check(lm_brms, ndraws = 100, type = "dens_overlay")
```

So, what do you think?

### Observation-level prediction error

To check the predictive accuracy of the model, we can investigate the distribution of observation-level prediction errors. A model with perfect fit would produce an error of $0$ for all $N$ observations.

Below, you see the distribution of errors for our linear model. What do you think?

```{r brms-lm-pp-2, echo = T, fig.align='center', fig.width = 9, fig.height=6}
brms::pp_check(lm_brms, ndraws = 1, type = "error_hist")
```

### Comparison: the model as a zero-one-inflated beta (ZOIB) regression

Zero-one-inflated beta (ZOIB) regression models bounded continuous outcomes on the
unit (i.e., $[0,1]$) interval.

The ZOIB model is a GLM with a multi-family likelihood, meaning
that its likelihood is composed of a mixture of several constitutive likelihoods.
Specifically, it supplements a beta pdf for values $y \in ]0, 1[$ with
additional pmfs for the boundary values $y \in \{0,1\}$.

To model a bounded continuous outcome on the unit interval, we must transform the scale of AfD support to range
from 0 to 1 (with midpoint 0.5) instead of -5 to +5 (with midpoint 0), but we will scale it back later on.

We first observe the distributional congruence of the ZOIB-generated outcome
simulations.

```{r brms-zoib-pp-1, echo = T, fig.align='center'}
brms::pp_check(zoib_brms, ndraws = 100, type = "dens_overlay")
```

We then turn to checking observation-level prediction errors.

```{r brms-zoib-pp-2, echo = T, fig.align='center'}
brms::pp_check(zoib_brms, ndraws = 1, type = "error_hist")
```

What do you conclude? Does the ZOIB-family accurately model the observed
sample-level distribution of the outcome? Are you happy with the predictive
accuracy of our current systematic component?
